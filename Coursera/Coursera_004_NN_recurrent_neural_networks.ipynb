{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las redes neuronales recurrentes constituyen una herramienta muy apropiada para modelar series temporales. Se trata de un tipo de redes con una arquitectura que implementa una cierta memoria y, por lo tanto, un sentido temporal. Esto se consigue implementando algunas neuronas que reciben como entrada la salida de una de las capas e inyectan su salida en una de las capas de un nivel anterior a ella"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.recurrent.LSTM at 0x28d21fc5cf8>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.layers.recurrent import LSTM\n",
    "\n",
    "units=56\n",
    "\n",
    "LSTM(units,\n",
    "     activation='tanh',\n",
    "     recurrent_activation='hard_sigmoid',\n",
    "     recurrent_initializer='orthogonal',\n",
    "     recurrent_regularizer=None,\n",
    "     dropout=0.0,\n",
    "     recurrent_dropout=0.0,\n",
    "     return_sequences=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embeber capas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers.embeddings import Embedding\n",
    "\n",
    "Embedding(input_dim,            # Tama√±o vocabulario\n",
    "          output_dim,           # longitud vector salida\n",
    "          embedding_initualizer='uniform',\n",
    "          mask_zero=False)      # mask zero values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing import sequence\n",
    "\n",
    "from keras.models import Sequential\n",
    "\n",
    "from keras.layers import Dense, Embedding, LSTM\n",
    "\n",
    "from keras.datasets import imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 20000\n",
    "maxlen = 80\n",
    "\n",
    "(x_train,y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 80)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = sequence.pad_sequences(x_train,maxlen=maxlen)\n",
    "x_test = sequence.pad_sequences(x_test,maxlen=maxlen)\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 2000000 into shape (60000,784)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-9aa056a301e6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mx_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtam_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtam_pixeles\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mx_test\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0mx_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtam_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtam_pixeles\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mx_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'float32'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mx_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'float32'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: cannot reshape array of size 2000000 into shape (60000,784)"
     ]
    }
   ],
   "source": [
    "x_train = x_train.reshape(tam_train,tam_pixeles)\n",
    "x_test  = x_test.reshape(tam_test,tam_pixeles)\n",
    "\n",
    "x_train = x_train.astype('float32') \n",
    "x_test = x_test.astype('float32') \n",
    "\n",
    "x_train /= 255\n",
    "x_test  /= 255\n",
    "\n",
    "y_train = to_categorical(y_train,num_classes)\n",
    "y_test  = to_categorical(y_test ,num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(max_features,128))\n",
    "model.add(LSTM(128,dropout=0.2,recurrent_dropout=0.2))\n",
    "model.add(Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/15\n",
      "25000/25000 [==============================] - 134s 5ms/step - loss: 0.6930 - acc: 0.5050 - val_loss: 0.6929 - val_acc: 0.5126\n",
      "Epoch 2/15\n",
      "25000/25000 [==============================] - 149s 6ms/step - loss: 0.6929 - acc: 0.5144 - val_loss: 0.6927 - val_acc: 0.5205\n",
      "Epoch 3/15\n",
      "25000/25000 [==============================] - 140s 6ms/step - loss: 0.6926 - acc: 0.5233 - val_loss: 0.6925 - val_acc: 0.5308\n",
      "Epoch 4/15\n",
      "25000/25000 [==============================] - 136s 5ms/step - loss: 0.6924 - acc: 0.5244 - val_loss: 0.6923 - val_acc: 0.5202\n",
      "Epoch 5/15\n",
      "25000/25000 [==============================] - 134s 5ms/step - loss: 0.6921 - acc: 0.5312 - val_loss: 0.6921 - val_acc: 0.5179\n",
      "Epoch 6/15\n",
      "25000/25000 [==============================] - 136s 5ms/step - loss: 0.6919 - acc: 0.5334 - val_loss: 0.6918 - val_acc: 0.5566\n",
      "Epoch 7/15\n",
      "25000/25000 [==============================] - 128s 5ms/step - loss: 0.6916 - acc: 0.5462 - val_loss: 0.6915 - val_acc: 0.5492\n",
      "Epoch 8/15\n",
      "25000/25000 [==============================] - 132s 5ms/step - loss: 0.6913 - acc: 0.5466 - val_loss: 0.6912 - val_acc: 0.5694\n",
      "Epoch 9/15\n",
      "25000/25000 [==============================] - 144s 6ms/step - loss: 0.6910 - acc: 0.5575 - val_loss: 0.6909 - val_acc: 0.5730\n",
      "Epoch 10/15\n",
      "25000/25000 [==============================] - 143s 6ms/step - loss: 0.6906 - acc: 0.5640 - val_loss: 0.6905 - val_acc: 0.5654\n",
      "Epoch 11/15\n",
      "25000/25000 [==============================] - 138s 6ms/step - loss: 0.6901 - acc: 0.5593 - val_loss: 0.6900 - val_acc: 0.5696\n",
      "Epoch 12/15\n",
      "25000/25000 [==============================] - 131s 5ms/step - loss: 0.6896 - acc: 0.5707 - val_loss: 0.6895 - val_acc: 0.5823\n",
      "Epoch 13/15\n",
      "25000/25000 [==============================] - 139s 6ms/step - loss: 0.6890 - acc: 0.5774 - val_loss: 0.6888 - val_acc: 0.5818\n",
      "Epoch 14/15\n",
      "25000/25000 [==============================] - 133s 5ms/step - loss: 0.6881 - acc: 0.5834 - val_loss: 0.6881 - val_acc: 0.5619\n",
      "Epoch 15/15\n",
      "25000/25000 [==============================] - 132s 5ms/step - loss: 0.6872 - acc: 0.5837 - val_loss: 0.6871 - val_acc: 0.5643\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x28d364899b0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "             optimizer='sgd',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train,y_train,\n",
    "         batch_size=32,\n",
    "         epochs = 15,\n",
    "         validation_data=(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - 25s 992us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.68711804100036622, 0.56432000000000004]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_testst,\n",
    "               y_test,\n",
    "               batch_size=32)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
